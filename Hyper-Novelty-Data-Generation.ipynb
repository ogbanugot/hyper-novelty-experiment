{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84492c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ogbanugot/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "# Define paper data\n",
    "papers = [\n",
    "    (\"A review of generative adversarial networks and its application in cybersecurity\", \"Artificial Intelligence Review\", 2020),\n",
    "    (\"Biometric fingerprint generation using generative adversarial networks\", \"Artificial Intelligence for Cyber Security\", 2021),\n",
    "    (\"Object detection for robot coordination in robotics soccer\", \"Nigerian Journal of Technological Development\", 2022),\n",
    "    (\"Conflict resolution via emerging technologies?\", \"Journal of Physics: Conference Series\", 2019),\n",
    "    (\"A predictive model for automatic generation control in smart grids using artificial neural networks\", \"Emerging Technologies for Developing Countries\", 2019),\n",
    "    (\"Estimating the time-lapse between medical insurance reimbursement with non-parametric regression models\", \"Advances in Information and Communication\", 2020)\n",
    "]\n",
    "\n",
    "# Create mapping of journals to papers\n",
    "journal_to_papers = defaultdict(list)\n",
    "for idx, (title, journal, year) in enumerate(papers):\n",
    "    journal_to_papers[journal].append(idx)\n",
    "\n",
    "# List of journals\n",
    "journals = list(journal_to_papers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3bd2b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'Artificial Intelligence Review': [0], 'Artificial Intelligence for Cyber Security': [1], 'Nigerian Journal of Technological Development': [2], 'Journal of Physics: Conference Series': [3], 'Emerging Technologies for Developing Countries': [4], 'Advances in Information and Communication': [5]})\n",
      "['Artificial Intelligence Review', 'Artificial Intelligence for Cyber Security', 'Nigerian Journal of Technological Development', 'Journal of Physics: Conference Series', 'Emerging Technologies for Developing Countries', 'Advances in Information and Communication']\n"
     ]
    }
   ],
   "source": [
    "print(journal_to_papers)\n",
    "print(journals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9188e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create row and column indices for the sparse matrix\n",
    "rows = []\n",
    "cols = []\n",
    "\n",
    "for journal_idx, journal in enumerate(journals):\n",
    "    for paper_idx in journal_to_papers[journal]:\n",
    "        rows.append(paper_idx)\n",
    "        cols.append(journal_idx)\n",
    "\n",
    "# Create sparse matrix G\n",
    "G = ssp.coo_matrix((np.ones(len(rows), dtype=np.int8), (rows, cols)), shape=(len(papers), len(journals)), dtype=np.int8)\n",
    "\n",
    "# Extract publication years\n",
    "paper_dates = np.array([year for _, _, year in papers], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4473a368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  (4, 4)\t1\n",
      "  (5, 5)\t1\n",
      "[2020 2021 2022 2019 2019 2020]\n"
     ]
    }
   ],
   "source": [
    "print(G)\n",
    "print(paper_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5397c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hypergraph matrix and paper dates\n",
    "with open('hypergraph.pkl', 'wb') as f:\n",
    "    pickle.dump((G.row.tolist(), G.col.tolist()), f)\n",
    "\n",
    "with open('paper_dates.pkl', 'wb') as f:\n",
    "    pickle.dump(paper_dates, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b4ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data based on the provided structure\n",
    "papers_df = pd.DataFrame({\n",
    "    'paper_id': [0, 1, 2, 3, 4, 5],\n",
    "    'title': [\n",
    "        'A review of generative adversarial networks and its application in cybersecurity',\n",
    "        'Biometric fingerprint generation using generative adversarial networks',\n",
    "        'Object detection for robot coordination in robotics soccer',\n",
    "        'Conflict resolution via emerging technologies?',\n",
    "        'A predictive model for automatic generation control in smart grids using artificial neural networks',\n",
    "        'Estimating the time-lapse between medical insurance reimbursement with non-parametric regression models'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Define terms for Predictive AI\n",
    "predictive_ai_df = pd.DataFrame({\n",
    "    'paper_id': [4, 5, 3],\n",
    "    'term': ['Regression Models', 'Non-Parametric Regression Models', 'Multi Agents']\n",
    "})\n",
    "\n",
    "# Define terms for Computer Vision\n",
    "computer_vision_df = pd.DataFrame({\n",
    "    'paper_id': [0, 1, 2],\n",
    "    'term': ['gans', 'Object Detection', 'Object Detection']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fdb903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ogbanugot/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "import pickle\n",
    "\n",
    "def create_hierarchical_incidence_matrix(papers_df, terms_df, term_column):\n",
    "    # Create mapping from term to index\n",
    "    term_to_index = {term: idx for idx, term in enumerate(terms_df[term_column].unique())}\n",
    "    \n",
    "    # Initialize matrix\n",
    "    num_papers = len(papers_df)\n",
    "    num_terms = len(term_to_index)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    \n",
    "    # Fill matrix\n",
    "    for _, row in terms_df.iterrows():\n",
    "        paper_id = row['paper_id']\n",
    "        term = row[term_column]\n",
    "        if term in term_to_index:\n",
    "            rows.append(paper_id)\n",
    "            cols.append(term_to_index[term])\n",
    "    \n",
    "    data = np.ones(len(rows), dtype=np.int8)  # Binary matrix\n",
    "    incidence_matrix = ssp.coo_matrix((data, (rows, cols)), shape=(num_papers, num_terms))\n",
    "    \n",
    "    return incidence_matrix, term_to_index\n",
    "\n",
    "# Create incidence matrices for new categories\n",
    "predictive_ai_matrix, predictive_ai_to_index = create_hierarchical_incidence_matrix(papers_df, predictive_ai_df, 'term')\n",
    "computer_vision_matrix, computer_vision_to_index = create_hierarchical_incidence_matrix(papers_df, computer_vision_df, 'term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6189b248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (4, 0)\t1\n",
      "  (5, 1)\t1\n",
      "  (3, 2)\t1\n",
      "{'Regression Models': 0, 'Non-Parametric Regression Models': 1, 'Multi Agents': 2}\n",
      "  (0, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 1)\t1\n",
      "{'gans': 0, 'Object Detection': 1}\n"
     ]
    }
   ],
   "source": [
    "print(predictive_ai_matrix)\n",
    "print(predictive_ai_to_index)\n",
    "print(computer_vision_matrix)\n",
    "print(computer_vision_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "248ced4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save matrices and mappings\n",
    "def save_to_pickle(matrix, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(matrix, f)\n",
    "\n",
    "def save_mapping(mapping, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(mapping, f)\n",
    "\n",
    "save_to_pickle(predictive_ai_matrix, 'predictive_ai.pkl')\n",
    "save_mapping(predictive_ai_to_index, 'predictive_ai_mapping.pkl')\n",
    "\n",
    "save_to_pickle(computer_vision_matrix, 'computer_vision.pkl')\n",
    "save_mapping(computer_vision_to_index, 'computer_vision_mapping.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4765da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create id2chemical.pkl (for demonstration, we're using a general term set)\n",
    "id2predictive_ai = predictive_ai_df.groupby('paper_id')['term'].apply(list).to_dict()\n",
    "id2computer_vision = computer_vision_df.groupby('paper_id')['term'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5837aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['Multi Agents'], 4: ['Regression Models'], 5: ['Non-Parametric Regression Models']}\n"
     ]
    }
   ],
   "source": [
    "print(id2predictive_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0d9c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle files\n",
    "with open('id2predictive_ai.pkl', 'wb') as f:\n",
    "    pickle.dump(id2predictive_ai, f)\n",
    "\n",
    "with open('id2computer_vision.pkl', 'wb') as f:\n",
    "    pickle.dump(id2computer_vision, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9cf66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "import pickle\n",
    "\n",
    "# Number of papers\n",
    "num_papers = len(papers_df)\n",
    "\n",
    "# Create a random citation matrix for demonstration\n",
    "# In a real scenario, you would replace this with actual citation data\n",
    "citation_matrix = np.random.randint(0, 5, size=(num_papers, num_papers))\n",
    "citation_matrix = ssp.csr_matrix(citation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09cb5f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t3\n",
      "  (0, 1)\t4\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t2\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t3\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t3\n",
      "  (2, 0)\t3\n",
      "  (2, 1)\t2\n",
      "  (2, 2)\t2\n",
      "  (2, 4)\t4\n",
      "  (2, 5)\t3\n",
      "  (3, 0)\t4\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t2\n",
      "  (3, 4)\t2\n",
      "  (3, 5)\t4\n",
      "  (4, 0)\t2\n",
      "  (4, 1)\t3\n",
      "  (4, 2)\t2\n",
      "  (4, 3)\t3\n",
      "  (4, 4)\t1\n",
      "  (4, 5)\t4\n",
      "  (5, 0)\t2\n",
      "  (5, 1)\t4\n",
      "  (5, 2)\t2\n",
      "  (5, 3)\t1\n",
      "  (5, 4)\t2\n",
      "  (5, 5)\t2\n"
     ]
    }
   ],
   "source": [
    "print(citation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e857c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle file\n",
    "with open('citations.pkl', 'wb') as f:\n",
    "    pickle.dump(citation_matrix, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
