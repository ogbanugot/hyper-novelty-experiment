{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84492c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "# Define paper data\n",
    "papers = [\n",
    "    (\"A review of generative adversarial networks and its application in cybersecurity\", \"Artificial Intelligence Review\", 2020),\n",
    "    (\"Biometric fingerprint generation using generative adversarial networks\", \"Artificial Intelligence for Cyber Security\", 2021),\n",
    "    (\"Object detection for robot coordination in robotics soccer\", \"Nigerian Journal of Technological Development\", 2022),\n",
    "    (\"Conflict resolution via emerging technologies?\", \"Journal of Physics: Conference Series\", 2019),\n",
    "    (\"A predictive model for automatic generation control in smart grids using artificial neural networks\", \"Emerging Technologies for Developing Countries\", 2019),\n",
    "    (\"Estimating the time-lapse between medical insurance reimbursement with non-parametric regression models\", \"Advances in Information and Communication\", 2020)\n",
    "]\n",
    "\n",
    "# Create mapping of journals to papers\n",
    "journal_to_papers = defaultdict(list)\n",
    "for idx, (title, journal, year) in enumerate(papers):\n",
    "    journal_to_papers[journal].append(idx)\n",
    "\n",
    "# List of journals\n",
    "journals = list(journal_to_papers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bd2b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'Artificial Intelligence Review': [0], 'Artificial Intelligence for Cyber Security': [1], 'Nigerian Journal of Technological Development': [2], 'Journal of Physics: Conference Series': [3], 'Emerging Technologies for Developing Countries': [4], 'Advances in Information and Communication': [5]})\n",
      "['Artificial Intelligence Review', 'Artificial Intelligence for Cyber Security', 'Nigerian Journal of Technological Development', 'Journal of Physics: Conference Series', 'Emerging Technologies for Developing Countries', 'Advances in Information and Communication']\n"
     ]
    }
   ],
   "source": [
    "print(journal_to_papers)\n",
    "print(journals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9188e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create row and column indices for the sparse matrix\n",
    "rows = []\n",
    "cols = []\n",
    "\n",
    "for journal_idx, journal in enumerate(journals):\n",
    "    for paper_idx in journal_to_papers[journal]:\n",
    "        rows.append(paper_idx)\n",
    "        cols.append(journal_idx)\n",
    "\n",
    "# Create sparse matrix G\n",
    "G = ssp.coo_matrix((np.ones(len(rows), dtype=np.int8), (rows, cols)), shape=(len(papers), len(journals)), dtype=np.int8)\n",
    "\n",
    "# Extract publication years\n",
    "paper_dates = np.array([year for _, _, year in papers], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0884ddaa-a366-4af7-aaa6-f5f8257c9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Define the dataframes\n",
    "papers_df = pd.DataFrame({\n",
    "    'paper_id': [0, 1, 2, 3, 4],\n",
    "    'open_alex_id': [\n",
    "        'https://openalex.org/W100013003',\n",
    "        'https://openalex.org/W1000167386',\n",
    "        'https://openalex.org/W1000334729',\n",
    "        'https://openalex.org/W1000340018',\n",
    "        'https://openalex.org/W1000355943',\n",
    "    ]\n",
    "})\n",
    "\n",
    "topics_df = pd.DataFrame({\n",
    "    'topic_id': [1, 2, 3],\n",
    "    'topic': ['Regression Models', 'Non-Parametric Regression Models', 'Multi Agents']\n",
    "})\n",
    "\n",
    "# Example paper-topic associations (this should be based on your actual data)\n",
    "# Here, we're assuming each paper is associated with a specific topic.\n",
    "# You would replace this with actual relationships from your data.\n",
    "# Example paper-topic associations\n",
    "associations_df = pd.DataFrame({\n",
    "    'paper_id': [0, 0, 1, 2, 3, 4],\n",
    "    'topic_id': [1, 2, 1, 0, 1, 0],  # Example topic associations\n",
    "})\n",
    "\n",
    "# Create row and column indices\n",
    "row_indices = associations_df['paper_id'].values\n",
    "col_indices = associations_df['topic_id'].values\n",
    "\n",
    "# Define the data (all ones in this case, indicating presence of association)\n",
    "data = np.ones(len(row_indices), dtype=np.int8)\n",
    "\n",
    "# Create the sparse matrix\n",
    "num_papers = len(papers_df)\n",
    "num_topics = len(topics_df)\n",
    "sparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(num_papers, num_topics), dtype=np.int8)\n",
    "\n",
    "# Print the sparse matrix\n",
    "print(sparse_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4473a368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int8'\n",
      "\twith 6 stored elements and shape (5, 3)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (4, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "print(sparse_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5397c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hypergraph matrix and paper dates\n",
    "with open('hypergraph.pkl', 'wb') as f:\n",
    "    pickle.dump((G.row.tolist(), G.col.tolist()), f)\n",
    "\n",
    "with open('paper_dates.pkl', 'wb') as f:\n",
    "    pickle.dump(paper_dates, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b4ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data based on the provided structure\n",
    "papers_df = pd.DataFrame({\n",
    "    'paper_id': [0, 1, 2, 3, 4, 5],\n",
    "    'title': [\n",
    "        'A review of generative adversarial networks and its application in cybersecurity',\n",
    "        'Biometric fingerprint generation using generative adversarial networks',\n",
    "        'Object detection for robot coordination in robotics soccer',\n",
    "        'Conflict resolution via emerging technologies?',\n",
    "        'A predictive model for automatic generation control in smart grids using artificial neural networks',\n",
    "        'Estimating the time-lapse between medical insurance reimbursement with non-parametric regression models'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Define terms for Predictive AI\n",
    "predictive_ai_df = pd.DataFrame({\n",
    "    'paper_id': [4, 5, 3],\n",
    "    'term': ['Regression Models', 'Non-Parametric Regression Models', 'Multi Agents']\n",
    "})\n",
    "\n",
    "# Define terms for Computer Vision\n",
    "computer_vision_df = pd.DataFrame({\n",
    "    'paper_id': [0, 1, 2],\n",
    "    'term': ['gans', 'Object Detection', 'Object Detection']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fdb903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ogbanugot/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "import pickle\n",
    "\n",
    "def create_hierarchical_incidence_matrix(papers_df, topics_df, term_column):\n",
    "    # Create mapping from term to index\n",
    "    term_to_index = {term: idx for idx, term in enumerate(terms_df[term_column].unique())}\n",
    "    \n",
    "    # Initialize matrix\n",
    "    num_papers = len(papers_df)\n",
    "    num_terms = len(term_to_index)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    \n",
    "    # Fill matrix\n",
    "    for _, row in terms_df.iterrows():\n",
    "        paper_id = row['paper_id']\n",
    "        term = row[term_column]\n",
    "        if term in term_to_index:\n",
    "            rows.append(paper_id)\n",
    "            cols.append(term_to_index[term])\n",
    "    \n",
    "    data = np.ones(len(rows), dtype=np.int8)  # Binary matrix\n",
    "    incidence_matrix = ssp.coo_matrix((data, (rows, cols)), shape=(num_papers, num_terms))\n",
    "    \n",
    "    return incidence_matrix, term_to_index\n",
    "\n",
    "# Create incidence matrices for new categories\n",
    "predictive_ai_matrix, predictive_ai_to_index = create_hierarchical_incidence_matrix(papers_df, predictive_ai_df, 'term')\n",
    "computer_vision_matrix, computer_vision_to_index = create_hierarchical_incidence_matrix(papers_df, computer_vision_df, 'term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6189b248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (4, 0)\t1\n",
      "  (5, 1)\t1\n",
      "  (3, 2)\t1\n",
      "{'Regression Models': 0, 'Non-Parametric Regression Models': 1, 'Multi Agents': 2}\n",
      "  (0, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 1)\t1\n",
      "{'gans': 0, 'Object Detection': 1}\n"
     ]
    }
   ],
   "source": [
    "print(predictive_ai_matrix)\n",
    "print(predictive_ai_to_index)\n",
    "print(computer_vision_matrix)\n",
    "print(computer_vision_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "248ced4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save matrices and mappings\n",
    "def save_to_pickle(matrix, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(matrix, f)\n",
    "\n",
    "def save_mapping(mapping, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(mapping, f)\n",
    "\n",
    "save_to_pickle(predictive_ai_matrix, 'predictive_ai.pkl')\n",
    "save_mapping(predictive_ai_to_index, 'predictive_ai_mapping.pkl')\n",
    "\n",
    "save_to_pickle(computer_vision_matrix, 'computer_vision.pkl')\n",
    "save_mapping(computer_vision_to_index, 'computer_vision_mapping.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4765da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create id2chemical.pkl (for demonstration, we're using a general term set)\n",
    "id2predictive_ai = predictive_ai_df.groupby('paper_id')['term'].apply(list).to_dict()\n",
    "id2computer_vision = computer_vision_df.groupby('paper_id')['term'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5837aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['Multi Agents'], 4: ['Regression Models'], 5: ['Non-Parametric Regression Models']}\n"
     ]
    }
   ],
   "source": [
    "print(id2predictive_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0d9c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle files\n",
    "with open('id2predictive_ai.pkl', 'wb') as f:\n",
    "    pickle.dump(id2predictive_ai, f)\n",
    "\n",
    "with open('id2computer_vision.pkl', 'wb') as f:\n",
    "    pickle.dump(id2computer_vision, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9cf66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "import pickle\n",
    "\n",
    "# Number of papers\n",
    "num_papers = len(papers_df)\n",
    "\n",
    "# Create a random citation matrix for demonstration\n",
    "# In a real scenario, you would replace this with actual citation data\n",
    "citation_matrix = np.random.randint(0, 5, size=(num_papers, num_papers))\n",
    "citation_matrix = ssp.csr_matrix(citation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09cb5f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t3\n",
      "  (0, 1)\t4\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t2\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t3\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t3\n",
      "  (2, 0)\t3\n",
      "  (2, 1)\t2\n",
      "  (2, 2)\t2\n",
      "  (2, 4)\t4\n",
      "  (2, 5)\t3\n",
      "  (3, 0)\t4\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t2\n",
      "  (3, 4)\t2\n",
      "  (3, 5)\t4\n",
      "  (4, 0)\t2\n",
      "  (4, 1)\t3\n",
      "  (4, 2)\t2\n",
      "  (4, 3)\t3\n",
      "  (4, 4)\t1\n",
      "  (4, 5)\t4\n",
      "  (5, 0)\t2\n",
      "  (5, 1)\t4\n",
      "  (5, 2)\t2\n",
      "  (5, 3)\t1\n",
      "  (5, 4)\t2\n",
      "  (5, 5)\t2\n"
     ]
    }
   ],
   "source": [
    "print(citation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e857c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle file\n",
    "with open('citations.pkl', 'wb') as f:\n",
    "    pickle.dump(citation_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b542842-ead4-400c-af6c-eb6614dfb7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file medline/journals.pkl from disk...\n",
      "Elapsed time: 105.71194052696228 seconds\n",
      "Loading paper dates medline/paper_dates.pkl from disk...\n",
      "Elapsed time: 3.307645797729492 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import scipy.sparse as ssp\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from scipy.stats import dirichlet\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import minimize\n",
    "from itertools import zip_longest\n",
    "from numba import guvectorize, vectorize\n",
    "from numba import int64, float64, int32\n",
    "from numba import cuda\n",
    "import math\n",
    "import pickle as pickle\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "\n",
    "class Stopwatch:\n",
    "    start_time = None\n",
    "\n",
    "    def go(self, msg=''):\n",
    "        if msg:\n",
    "            print(msg, flush=True)\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def stop(self, msg=''):\n",
    "        if msg:\n",
    "            print(\"{}: {} seconds\".format(msg, time.time() - self.start_time), flush=True)\n",
    "        else:\n",
    "            print(\"Elapsed time: {} seconds\".format(time.time() - self.start_time), flush=True)\n",
    "\n",
    "    def check(self):\n",
    "        return time.time() - self.start_time\n",
    "\n",
    "\n",
    "tic = Stopwatch()\n",
    "\n",
    "\n",
    "def load_date(filename):\n",
    "    tic = Stopwatch()\n",
    "    print(\"Loading paper dates %s from disk...\" % filename),\n",
    "    tic.go()\n",
    "    pkl_file = open(filename, 'rb')\n",
    "    A = pickle.load(pkl_file, encoding='latin1')\n",
    "    pkl_file.close()\n",
    "    tic.stop()\n",
    "    return A\n",
    "\n",
    "\n",
    "def load_hypergraph(filename):\n",
    "    tic = Stopwatch()\n",
    "    print(\"Loading file %s from disk...\" % filename),\n",
    "    tic.go()\n",
    "    pkl_file = open(filename, 'rb')\n",
    "    (row, col) = pickle.load(pkl_file, encoding='latin1')\n",
    "    pkl_file.close()\n",
    "    A = ssp.coo_matrix((np.ones(len(row), dtype=np.int8), (row, col)), shape=(19916562, max(col) + 1), dtype=np.int8)\n",
    "    tic.stop()\n",
    "    return A\n",
    "\n",
    "\n",
    "tic = Stopwatch()\n",
    "G = load_hypergraph('medline/journals.pkl').tocsr()\n",
    "paper_dates = load_date('medline/paper_dates.pkl')\n",
    "\n",
    "# G = G[paper_dates > 0, :]\n",
    "# paper_dates = paper_dates[paper_dates > 0]\n",
    "# G = G[paper_dates < 2010, :]\n",
    "# paper_dates = paper_dates[paper_dates < 2010]\n",
    "# paper_dates[paper_dates < 1950] = 1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f8e2bef-aa95-4b44-a72d-7cc649934c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1975 1975 1975 ...   -1   -1 2009]\n"
     ]
    }
   ],
   "source": [
    "print(paper_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ed10c60-bbf9-4d3a-9cdc-8c3702cd658e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int8'\n",
      "\twith 96663162 stored elements and shape (19916562, 30126)>\n",
      "  Coords\tValues\n",
      "  (0, 5168)\t1\n",
      "  (0, 7337)\t2\n",
      "  (0, 8907)\t1\n",
      "  (0, 8989)\t2\n",
      "  (0, 15846)\t1\n",
      "  (0, 20721)\t1\n",
      "  (0, 22609)\t1\n",
      "  (0, 23131)\t2\n",
      "  (0, 24442)\t1\n",
      "  (0, 24723)\t1\n",
      "  (1, 2833)\t1\n",
      "  (1, 5486)\t2\n",
      "  (1, 7337)\t3\n",
      "  (1, 10365)\t1\n",
      "  (1, 18842)\t6\n",
      "  (1, 24660)\t6\n",
      "  (2, 7015)\t1\n",
      "  (2, 7337)\t1\n",
      "  (2, 8989)\t2\n",
      "  (2, 9528)\t1\n",
      "  (2, 15471)\t2\n",
      "  (2, 18842)\t3\n",
      "  (2, 20155)\t1\n",
      "  (2, 24075)\t1\n",
      "  (2, 27910)\t1\n",
      "  :\t:\n",
      "  (16953034, 26828)\t3\n",
      "  (16953122, 885)\t1\n",
      "  (16953122, 2833)\t2\n",
      "  (16953122, 4961)\t1\n",
      "  (16953122, 5458)\t1\n",
      "  (16953122, 6428)\t1\n",
      "  (16953122, 7337)\t1\n",
      "  (16953122, 8097)\t1\n",
      "  (16953122, 15471)\t1\n",
      "  (16953122, 23872)\t1\n",
      "  (16953122, 24468)\t1\n",
      "  (16953122, 27290)\t1\n",
      "  (16953122, 28953)\t1\n",
      "  (16953158, 2084)\t1\n",
      "  (16953158, 10087)\t2\n",
      "  (16953158, 10914)\t1\n",
      "  (16953158, 13735)\t2\n",
      "  (16953158, 16797)\t10\n",
      "  (16953158, 17101)\t1\n",
      "  (16953158, 18443)\t1\n",
      "  (16953158, 20712)\t2\n",
      "  (16953158, 25113)\t1\n",
      "  (16953158, 26851)\t2\n",
      "  (16953158, 29101)\t1\n",
      "  (16953412, 20752)\t1\n"
     ]
    }
   ],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcbfeb9f-fa26-425a-961a-9cf35128ae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file medline/chemical.pkl from disk...\n",
      "Elapsed time: 7.957335472106934 seconds\n",
      "Loading file medline/disease.pkl from disk...\n",
      "Elapsed time: 4.053662300109863 seconds\n",
      "Loading file medline/method.pkl from disk...\n",
      "Elapsed time: 5.240198135375977 seconds\n"
     ]
    }
   ],
   "source": [
    "C = load_hypergraph('medline/chemical.pkl').tocsr()\n",
    "D = load_hypergraph('medline/disease.pkl').tocsr()\n",
    "M = load_hypergraph('medline/method.pkl').tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2133d61-0322-46c2-b15b-fc9ec01efeb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int8'\n",
      "\twith 32157364 stored elements and shape (19916562, 9159)>\n",
      "  Coords\tValues\n",
      "  (0, 150)\t1\n",
      "  (0, 159)\t1\n",
      "  (0, 861)\t1\n",
      "  (0, 1954)\t1\n",
      "  (1, 3069)\t1\n",
      "  (1, 3075)\t1\n",
      "  (2, 788)\t1\n",
      "  (2, 869)\t1\n",
      "  (2, 2859)\t1\n",
      "  (2, 5007)\t1\n",
      "  (3, 964)\t1\n",
      "  (3, 1027)\t1\n",
      "  (3, 1412)\t1\n",
      "  (3, 2087)\t1\n",
      "  (3, 4451)\t1\n",
      "  (4, 2221)\t1\n",
      "  (4, 2870)\t1\n",
      "  (4, 3043)\t1\n",
      "  (5, 1147)\t1\n",
      "  (5, 2234)\t1\n",
      "  (5, 2561)\t1\n",
      "  (5, 2695)\t1\n",
      "  (5, 3339)\t1\n",
      "  (5, 3343)\t1\n",
      "  (6, 918)\t1\n",
      "  :\t:\n",
      "  (19904833, 1755)\t1\n",
      "  (19904833, 2692)\t1\n",
      "  (19904833, 3818)\t1\n",
      "  (19904833, 5558)\t1\n",
      "  (19904834, 5426)\t1\n",
      "  (19904834, 5860)\t1\n",
      "  (19904835, 5134)\t1\n",
      "  (19904835, 5558)\t1\n",
      "  (19908621, 368)\t1\n",
      "  (19908624, 368)\t1\n",
      "  (19908626, 382)\t1\n",
      "  (19908626, 6194)\t1\n",
      "  (19908627, 382)\t1\n",
      "  (19908627, 2719)\t1\n",
      "  (19908627, 6194)\t1\n",
      "  (19910909, 4694)\t1\n",
      "  (19910910, 214)\t1\n",
      "  (19910910, 446)\t1\n",
      "  (19910910, 4131)\t1\n",
      "  (19910911, 2486)\t1\n",
      "  (19911454, 41)\t1\n",
      "  (19911454, 5863)\t1\n",
      "  (19911459, 2486)\t1\n",
      "  (19911459, 6488)\t1\n",
      "  (19916200, 376)\t1\n"
     ]
    }
   ],
   "source": [
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1bd2aa5-c4d1-46a3-858a-778c6a3d4476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_454/700234916.py:2: DeprecationWarning: Please import `csc_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csc` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  citations=pickle.load(open('medline/citations.pkl','rb'),encoding='latin1').tocsr()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 9.711724281311035 seconds\n",
      "Loading file medline/chemical.pkl from disk...\n",
      "Elapsed time: 7.945269584655762 seconds\n",
      "Loading file medline/disease.pkl from disk...\n",
      "Elapsed time: 4.725998163223267 seconds\n",
      "Loading file medline/method.pkl from disk...\n",
      "Elapsed time: 6.2029829025268555 seconds\n",
      "Loading file medline/journals.pkl from disk...\n",
      "Elapsed time: 106.63767647743225 seconds\n",
      "Loading paper dates medline/paper_dates.pkl from disk...\n",
      "Elapsed time: 2.090975284576416 seconds\n"
     ]
    }
   ],
   "source": [
    "tic.go('Loading citation data...')\n",
    "citations=pickle.load(open('medline/citations.pkl','rb'),encoding='latin1').tocsr()\n",
    "tic.stop()\n",
    "# Load hypergraphs\n",
    "PM=[] # paper by mesh terms\n",
    "for i in ['chemical','disease','method']:\n",
    "    PM.append(load_hypergraph('medline/'+i+'.pkl'))\n",
    "PM=ssp.hstack(PM).tocsr()\n",
    "PJ=load_hypergraph('medline/journals.pkl').tocsr() # paper by journal\n",
    "\n",
    "paper_dates=load_date('medline/paper_dates.pkl') # publication date\n",
    "\n",
    "id2chemical=pickle.load(open('medline/id2chemical.pkl','rb'),encoding='latin1')\n",
    "id2disease=pickle.load(open('medline/id2disease.pkl','rb'),encoding='latin1')\n",
    "id2method=pickle.load(open('medline/id2method.pkl','rb'),encoding='latin1')\n",
    "id2name=np.array(id2chemical+id2disease+id2method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27fae841-29be-4c0c-a0b9-3f1f8e36e51d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 56185074 stored elements and shape (19916562, 2007)>\n",
      "  Coords\tValues\n",
      "  (1, 1976)\t2.0\n",
      "  (1, 1977)\t3.0\n",
      "  (1, 1978)\t3.0\n",
      "  (1, 1979)\t3.0\n",
      "  (1, 1980)\t6.0\n",
      "  (1, 1981)\t3.0\n",
      "  (1, 1982)\t3.0\n",
      "  (1, 1983)\t4.0\n",
      "  (1, 1984)\t5.0\n",
      "  (1, 1985)\t1.0\n",
      "  (1, 1986)\t2.0\n",
      "  (1, 1987)\t3.0\n",
      "  (1, 1989)\t3.0\n",
      "  (1, 1990)\t2.0\n",
      "  (1, 1993)\t1.0\n",
      "  (1, 1994)\t1.0\n",
      "  (1, 1995)\t1.0\n",
      "  (1, 1998)\t1.0\n",
      "  (2, 1976)\t1.0\n",
      "  (2, 1977)\t2.0\n",
      "  (2, 1978)\t1.0\n",
      "  (2, 1979)\t2.0\n",
      "  (2, 1981)\t3.0\n",
      "  (2, 1982)\t1.0\n",
      "  (3, 1976)\t1.0\n",
      "  :\t:\n",
      "  (16952961, 2006)\t1.0\n",
      "  (16952964, 2006)\t1.0\n",
      "  (16952965, 2005)\t2.0\n",
      "  (16952965, 2006)\t2.0\n",
      "  (16953008, 2006)\t1.0\n",
      "  (16953019, 2006)\t1.0\n",
      "  (16953123, 2000)\t1.0\n",
      "  (16953123, 2001)\t4.0\n",
      "  (16953123, 2002)\t2.0\n",
      "  (16953123, 2003)\t1.0\n",
      "  (16953123, 2004)\t1.0\n",
      "  (16953123, 2005)\t4.0\n",
      "  (16953159, 2006)\t1.0\n",
      "  (16953244, 2005)\t3.0\n",
      "  (16953244, 2006)\t1.0\n",
      "  (16953247, 2002)\t3.0\n",
      "  (16953247, 2003)\t7.0\n",
      "  (16953247, 2004)\t7.0\n",
      "  (16953247, 2005)\t10.0\n",
      "  (16953247, 2006)\t2.0\n",
      "  (16953263, 2005)\t5.0\n",
      "  (16953266, 2005)\t5.0\n",
      "  (16953275, 2005)\t1.0\n",
      "  (16953413, 2002)\t1.0\n",
      "  (16953481, 2005)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf3a600-b12f-4412-8568-74bf9ec1233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file medline/chemical.pkl from disk...\n",
      "Elapsed time: 8.875566244125366 seconds\n",
      "Loading file medline/disease.pkl from disk...\n",
      "Elapsed time: 4.8578102588653564 seconds\n",
      "Loading file medline/method.pkl from disk...\n",
      "Elapsed time: 6.609812259674072 seconds\n",
      "Loading paper dates medline/paper_dates.pkl from disk...\n",
      "Elapsed time: 2.4513227939605713 seconds\n"
     ]
    }
   ],
   "source": [
    "G=[]\n",
    "for thing in ['chemical','disease','method']:\n",
    "    G.append(load_hypergraph('medline/'+thing+'.pkl'))\n",
    "G=ssp.hstack(G).tocsr()\n",
    "\n",
    "paper_dates=load_date('medline/paper_dates.pkl') # Load publicatioin dates\n",
    "\n",
    "G=G[paper_dates>0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e68d6c84-a27c-4d8b-aa24-00bfcff050d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file journal.pkl from disk...\n",
      "Elapsed time: 0.0008120536804199219 seconds\n"
     ]
    }
   ],
   "source": [
    "G = load_hypergraph('journal.pkl').tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ea11b5-4d2d-4b39-a40e-3f72708a6447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file predictive_ai.pkl from disk...\n",
      "Elapsed time: 0.0006499290466308594 seconds\n",
      "Loading file computer_vision.pkl from disk...\n",
      "Elapsed time: 0.00060272216796875 seconds\n"
     ]
    }
   ],
   "source": [
    "G=[]\n",
    "for thing in ['predictive_ai','computer_vision']:\n",
    "    G.append(load_hypergraph(''+thing+'.pkl'))\n",
    "G=ssp.hstack(G).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cabe5ac-b392-4c00-b8cd-2c1d69941089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citation data...\n",
      "Elapsed time: 0.0004878044128417969 seconds\n",
      "Loading file predictive_ai.pkl from disk...\n",
      "Elapsed time: 0.00038433074951171875 seconds\n",
      "Loading file computer_vision.pkl from disk...\n",
      "Elapsed time: 0.000576019287109375 seconds\n",
      "Loading file journal.pkl from disk...\n",
      "Elapsed time: 0.00046062469482421875 seconds\n",
      "Loading paper dates paper_dates.pkl from disk...\n",
      "Elapsed time: 0.0002658367156982422 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_454/1043711900.py:2: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  citations=pickle.load(open('citations.pkl','rb'),encoding='latin1').tocsr()\n"
     ]
    }
   ],
   "source": [
    "tic.go('Loading citation data...')\n",
    "citations=pickle.load(open('citations.pkl','rb'),encoding='latin1').tocsr()\n",
    "tic.stop()\n",
    "# Load hypergraphs\n",
    "PM=[] # paper by mesh terms\n",
    "for i in ['predictive_ai','computer_vision']:\n",
    "    PM.append(load_hypergraph(''+i+'.pkl'))\n",
    "PM=ssp.hstack(PM).tocsr()\n",
    "PJ=load_hypergraph('journal.pkl').tocsr() # paper by journal\n",
    "\n",
    "paper_dates=load_date('paper_dates.pkl') # publication date\n",
    "\n",
    "id2predictive_ai=pickle.load(open('id2predictive_ai.pkl','rb'),encoding='latin1')\n",
    "id2computer_vision=pickle.load(open('id2computer_vision.pkl','rb'),encoding='latin1')\n",
    "id2name=np.array(id2predictive_ai+id2computer_vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023db7c3-e29e-42de-bff4-f55fde17ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 34 stored elements and shape (6, 6)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t3\n",
      "  (0, 1)\t4\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t2\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t3\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t3\n",
      "  (2, 0)\t3\n",
      "  (2, 1)\t2\n",
      "  (2, 2)\t2\n",
      "  (2, 4)\t4\n",
      "  (2, 5)\t3\n",
      "  (3, 0)\t4\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t2\n",
      "  (3, 4)\t2\n",
      "  (3, 5)\t4\n",
      "  (4, 0)\t2\n",
      "  (4, 1)\t3\n",
      "  (4, 2)\t2\n",
      "  (4, 3)\t3\n",
      "  (4, 4)\t1\n",
      "  (4, 5)\t4\n",
      "  (5, 0)\t2\n",
      "  (5, 1)\t4\n",
      "  (5, 2)\t2\n",
      "  (5, 3)\t1\n",
      "  (5, 4)\t2\n",
      "  (5, 5)\t2\n"
     ]
    }
   ],
   "source": [
    "print(citations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
